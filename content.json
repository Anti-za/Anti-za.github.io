{"meta":{"title":"AIomedical","subtitle":"小蚁","description":"","author":"Jiacai Yi","url":"http://example.com","root":"/"},"pages":[{"title":"","date":"2021-12-05T09:35:20.213Z","updated":"2021-07-20T16:19:18.000Z","comments":true,"path":"404.html","permalink":"http://example.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"留言板","date":"2021-07-20T07:27:18.000Z","updated":"2021-07-24T05:54:22.000Z","comments":false,"path":"shuoshuo/index.html","permalink":"http://example.com/shuoshuo/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2021-12-05T09:35:20.229Z","updated":"2021-07-20T16:17:54.000Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2021-12-05T09:35:20.229Z","updated":"2021-07-20T15:54:46.000Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"","date":"2021-12-05T09:35:20.276Z","updated":"2021-07-26T05:53:46.000Z","comments":false,"path":"acknowledgement/index.html","permalink":"http://example.com/acknowledgement/index.html","excerpt":"","text":"Acknowledgement 感谢以下平台提供的服务支持 Hexo静态博客网站生成 jsDelivr开源的免费CDN GitHub全球最大同性交友社区 Gitee代码托管平台 感谢以下的开源项目提供的大力帮助 点击下方标签即可进入对应仓库 站在巨人的肩膀上"},{"title":"所有标签","date":"2021-12-05T09:35:20.245Z","updated":"2021-07-20T16:18:14.000Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Hello World","slug":"hello-world","date":"2021-12-05T02:31:19.554Z","updated":"2021-07-26T06:54:28.000Z","comments":true,"path":"article/4a17b156.html","link":"","permalink":"http://example.com/article/4a17b156.html","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"杂货间","slug":"杂货间","permalink":"http://example.com/categories/%E6%9D%82%E8%B4%A7%E9%97%B4/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://example.com/tags/Hexo/"}]},{"title":"ADMETlab 2.0: an integrated online platform for accurate and comprehensive predictions of ADMET properties","slug":"ADMETlab2","date":"2021-07-26T06:16:08.000Z","updated":"2021-07-26T07:58:10.000Z","comments":true,"path":"article/92149899.html","link":"","permalink":"http://example.com/article/92149899.html","excerpt":"今年课题组发在NAR上的一篇文章, IF: 16.971","text":"今年课题组发在NAR上的一篇文章, IF: 16.971 ADMETlab 2.0: an integrated online platform for accurate and comprehensive predictions of ADMET properties 论文链接: ADMETlab 2.0: an integrated online platform for accurate and comprehensive predictions of ADMET propertieshttps://academic.oup.com/nar/article/49/W1/W5/6249611 访问地址: ADMETlab 2.0https://admetmesh.scbdd.com/ 1. Overview由于候选化合物的不良药代动力学和毒性是药物开发失败的主要原因，因此，吸收、分布、代谢、排泄和毒性(ADMET)的评价应尽早得到评估。在计算机中进行的大量实验中，ADMET评价模型已被开发为辅助药物化学家设计和优化先导物的辅助工具。在这里，我们宣布了ADMETlab 2.0的发布，这是广泛使用的AMDETlab web服务器的一个完全重新设计的版本，用于预测药物动力学和化学品毒性特性，其中支持的admet相关端点的数量大约是上一个版本的两倍。包括17个理化性质，13个药用化学性质，23个ADME性质，27个毒性终点和8个毒性基团规则。采用多任务图注意框架(MGA)，在AdmetLab 2.0中开发强大和准确的模型。批量计算模块是响应于用户的批量请求提供的，并且结果进一步优化了结果的表示。 Figure 1. Workflow scheme of ADMETlab 2.0 2. New Developments1. Comprehensively enhanced ADMET profilesIn this update, the available ADMET profile is extended to 88 related characteristics spanning 7 different categories, roughly twice the number of its predecessor. Compared with the initial version, the number of entries for model training in the current release has almost tripled. 2. Re-engineered modules and batch evaluation supportThe functional modules were re-engineered and optimized to improve the user experience. An independent module has been added for supporting batch uploading and downloading. The users could define their own criterion to promising and desirable molecules. 3. Robust and accurate MGA modelsThe MGA framework was employed to develop classification and regression predictors simultaneously. Deep learning makes multitask learning very natural and the combination leads to improved performance for many modeled endpoints. 4. Practical explanation and guidanceDetailed explanation and optimal range of each property are provided to help the users to get a whole ADMET picture of input molecule. The empirical-based decision states of each property are visually represented with different colored dots (green: excellent; yellow: medium; red: poor). 3. Program Description1. Model dataTable 1. Data information of 53 predictive models Properties Total (positive/Negative) training set (positive/Negative) test set (positive/Negative) valuation set (positive/Negative) LogS 4797 3836 480 481 LogD7.4 10370 8296 1036 1038 LogP 12682 10145 1270 1267 Caco-2 Permeability 2464 1970 247 247 MDCK Permeability 1140 912 114 114 Pgp-inhibitor 2209 (1315/894) 1764 (1051/713) 222 (132/90) 223 (132/91) pgp-substrate 1185 (586/599) 949 (471/478) 118 (58/60) 118 (57/61) HIA 1160 (1022/138) 927 (818/109) 116 (101/15) 117 (103/14) F20% 992 (753/239) 794 (602/192) 98 (75/23) 100 (76/24) F30% 992 (666/326) 793 (532/261) 99 (67/32) 100 (67/33) PPB 4712 3771 479 480 VD 1086 872 107 107 BBB Penetration 2865 (1651/1254) 2324 (1321/1003) 290 (165/125) 291 (165/126) Fu 2575 2059 258 258 CYP1A2 inhibitor 12635 (5876/6759) 10111 (4702/5425) 1261 (588/673) 1263 (586/677) CYP1A2 substrate 366 (176/190) 292 (140/152) 37 (18/19) 37 (18/19) CYP2C19 inhibitor 12611 (5770/6841) 10096 (4618/5478) 1257 (577/680) 1258 (575/683) CYP2C19 substrate 258 (107/151) 206 (85/121) 26 (11/15) 26 (11/15) CYP2C9 inhibitor 12111 (4017/8094) 9686 (3213/6473) 1213 (402/811) 1212 (402/810) CYP2C9 substrate 811 (325/486) 647 (259/388) 82 (33/49) 82 (33/49) CYP2D6 inhibitor 13073 (2535/10538) 10471 (2032/8439) 1304 (255/1051) 1298 (250/1048) CYP2D6 substrate 877 (435/442) 703 (347/356) 85 (44/41) 89 (44/45) CYP3A4 inhibitor 12339 (5092/7247) 9880 (4074/5806) 1232 (510/722) 1227 (508/719) CYP3A4 substrate 979 (497/482) 786 (397/389) 97 (49/48) 96 (51/45) CL 831 666 81 84 T1/2 1219 (500/719) 973 (399/574) 124 (51/73) 122 (50/72) hERG Blockers 13845 (6922/6923) 11076 (5538/5538) 1384 (692/692) 1385 (692/693) H-HT 2304 (1299/1005) 1850 (1044/806) 227 (128/99) 227 (127/100) DILI 467 (235/232) 373 (187/186) 47 (24/23) 47 (24/23) AMES Toxicity 7575 (4222/3353) 6071 (3389/2682) 751 (416/335) 753 (417/336) Rat Oral Acute Toxicity 7327 (2799/4528) 5862 (2240/3622) 733 (280/453) 732 (279/453) FDAMDD 1197 (561/636) 957 (448/509) 120 (56/64) 120 (57/63) Skin Sensitization 405 (274/131) 324 (219/105) 40 (27/13) 41 (28/13) Carcinogencity 1041 (516/525) 832 (413/419) 104 (51/53) 105 (52/53) Bioconcentration Factor 676 540 68 68 IGC50 1787 1429 179 179 LC50FM 816 652 82 82 LC50DM 347 277 35 35 Eye Corrosion 2298 (886/1412) 1838 (709/1129) 230 (89/141) 230 (84/142) Eye Irritation 5219 (3874/1345) 4176 (3099/1077) 522 (388/134) 521 (387/134) Respiratory Toxicity 1388 (835/553) 1109 (666/443) 139 (84/55) 140 (85/55) NR-AR 7312 (266/7046) 5853 (213/5640) 726 (26/700) 733 (27/706) NR-AR-LBD 6862 (233/6629) 5493 (186/5307) 688 (23/665) 681 (24/657） NR-AhR 6603 (763/5840) 5285 (610/4675) 657 (77/580) 661 (76/585) NR-Aromatase 5887 (256/5631) 4711 (205/4506) 588 (25/563) 588 (26/562) NR-ER 6166 (669/5497) 4935 (536/4399) 616 (66/550) 615 (67/548) NR-ER-LBD 7052 (342/6710) 5643 (274/5369) 701 (33/668） 708 (35/673) NR-PPAR-gamma 6586 (197/6389) 5266 (158/5108) 661 (19/642) 659 (20/639) SR-ARE 5652 (865/4787) 4521 (691/3830) 564 (87/477) 567 (87/480) SR-ATAD5 7170 (249/6921) 5736 (199/5537) 718 (25/693) 716 (25/691) SR-HSE 6319 (360/5959) 5059 (289/4770) 630 (35/595) 630 (36/594) SR-MMP 5913 (892/5021) 4735 (713/4022) 592 (91/501) 586 (88/498) SR-p53 6915 (456/6459) 5543 (364/5179) 692 (46/646) 680 (46/634) 2. MGA frameworkAn overview of the Multi-task Graph Attention (MGA) framework is shown in Figure 2. As shown in Figure 2, MGA is composed of input, Relation graph convolution network (RGCN) layers, attention layer and fully-connected (FC) layers. In the Input, a node represents the information of an atom, and after passing RGCN layers, the node represents general features of circular substructure centered on the atom. RGCN is an extension of the standard graph convolution network (GCN) by introducing edge features to enrich the messages used to update the hidden states in the network. The propagation rule for each node in RGCN layer is calculated via $h_{v}^{(l+1)}=\\sigma\\left(\\sum_{r \\in R} \\sum_{u \\epsilon N_{v}^{r}} W_{r}^{(l)} h_{u}^{(l)}+W_{u}^{(l)} h_{v}^{(l)}\\right)$ where $h_{v}^{(l+1)}$ is the state vector of target node v after l+1 iterations and $N_{v}^{r}$ denotes the neighbors of node v under the relation (edge) $r \\epsilon R$. $W_{r}^{(l)}$ is the weight for neighbor node u connecting to node v by an edge attributed with the relation $r \\in R$, and $W_{0}^{(l)}$ is the weight for target node v. As can be seen above, the edge information is explicitly incorporated in a RGCN under the relation $r \\in R$. The weight $W_{r}^{(l)}$ is a linear combination of basis transformation. As shown in Figure 2B, attention layers can assign different attention weights to different substructures, and then generate the customized fingerprints (CFP) from the general features for a specific task. The attention weights and customized fingerprints are generated as follows: $\\omega_{v}=\\sigma\\left(W \\cdot h_{v}+\\right.$ bias $)$ $C F P=\\sum_{v=1}^{N}\\left(\\omega_{v} \\bullet h_{v}\\right)$ where W and bias are the parameters of attention layers learned in model training, N is the number of nodes (substructures), $\\omega_{v}$ is the attention weight of node (substructure) v, and $h_{v}$ is the general feature of node (substructure) v. As shown in Figure 2A, fully-connected (FC) layers predict the corresponding tasks based on the customized toxicity fingerprints. The classification and regression tasks adopt different loss functions (loss_c and loss_r) as follows: $\\operatorname{loss_{-}c}=\\sum_{n=1}^{N} \\sum_{c=1}^{C}\\left(-\\left[p_{c} y_{n, c} \\cdot \\log \\sigma\\left(x_{n, c}\\right)+\\left(1-y_{n, c}\\right) \\cdot \\log \\left(1-\\sigma\\left(x_{n, c}\\right)\\right)\\right]\\right)$ $\\operatorname{loss_{-}r}=\\sum_{n=1}^{N} \\sum_{r=1}^{R}\\left(x_{n, r}-y_{n, r}\\right)^{2}$ where $X_{n, c}$ is the predict value of molecule n for classification task c, $y_{n, c}$ is the true values of molecule n for classification task c, $p_{c}$ is the weight of positive samples, $x_{n, r}$ is the predict value of molecule n for regression task r, $y_{n, r}$ is the true value of molecule n for regression task r, N is the number of molecules, C is the number of the classification tasks, and R is the number of the regression tasks. The loss function of MGA is a combination of loss_c and loss_r: $\\operatorname{loss}=\\operatorname{loss_{-}c}+\\operatorname{loss_{-}r}$ Figure 2. An overview of the Multi-task Graph Attention framework. 3. Model performanceTable 2. Predictive performance of regression models Properties Test set Validation set Training set R2 RMSE MAE R2 RMSE MAE R2 RMSE MAE LogS 0.854 0.850 0.588 0.871 0.814 0.555 0.967 0.399 0.287 LogD7.4 0.892 0.462 0.347 0.901 0.457 0.345 0.950 0.305 0.236 LogP 0.957 0.357 0.256 0.957 0.387 0.261 0.980 0.257 0.193 Caco-2 Permeability 0.746 0.307 0.222 0.786 0.296 0.203 0.943 0.152 0.117 MDCK Permeability 0.731 0.291 0.199 0.662 0.301 0.233 0.934 0.140 0.105 PPB 0.733 0.135 0.083 0.744 0.155 0.091 0.961 0.054 0.037 VD 0.782 0.670 0.457 0.785 0.637 0.409 0.895 0.492 0.330 Fu 0.763 0.367 0.263 0.778 0.354 0.258 0.861 0.268 0.197 CL 0.678 3.375 2.240 0.692 2.956 1.883 0.977 0.740 0.556 Bioconcentration Factor 0.786 0.603 0.435 0.779 0.641 0.508 0.929 0.365 0.280 IGC50 0.723 0.496 0.335 0.860 0.356 0.270 0.920 0.305 0.232 LC50FM 0.745 0.863 0.643 0.660 0.693 0.536 0.918 0.423 0.324 LC50DM 0.524 0.994 0.692 0.909 0.496 0.386 0.950 0.398 0.319 Table 3. Predictive performance of classification models Property Test&nbsp;set Validation&nbsp;set Training set AUC ACC SP Sen MCC AUC ACC SP Sen MCC AUC ACC SP Sen MCC Pgp-inhibitor 0.922 0.867 0.844 0.882 0.723 0.912 0.836 0.769 0.882 0.657 1.000 0.994 0.993 0.994 0.987 Pgp-substrate 0.840 0.768 0.705 0.828 0.538 0.901 0.840 0.853 0.828 0.680 1.000 1.000 1.000 1.000 1.000 HIA 0.866 0.924 0.800 0.942 0.687 0.944 0.949 0.867 0.961 0.785 1.000 0.988 1.000 0.987 0.950 F20% 0.833 0.750 0.680 0.773 0.414 0.905 0.842 0.760 0.868 0.599 1.000 0.995 1.000 0.993 0.987 F30% 0.848 0.802 0.794 0.806 0.580 0.797 0.800 0.727 0.836 0.555 1.000 0.998 1.000 0.996 0.994 BBB Penetration 0.908 0.862 0.824 0.891 0.718 0.920 0.852 0.810 0.885 0.698 0.992 0.957 0.948 0.964 0.912 CYP1A2 inhibitor 0.928 0.852 0.848 0.857 0.704 0.948 0.886 0.876 0.896 0.771 0.972 0.914 0.898 0.932 0.828 CYP1A2 substrate 0.737 0.649 0.632 0.667 0.298 0.842 0.816 0.800 0.833 0.632 0.985 0.936 0.942 0.929 0.871 CYP2C19 inhibitor 0.913 0.839 0.813 0.869 0.679 0.925 0.854 0.825 0.889 0.712 0.952 0.877 0.845 0.916 0.758 CYP2C19 substrate 0.758 0.654 0.667 0.636 0.300 0.926 0.741 0.688 0.818 0.497 0.974 0.928 0.894 0.977 0.859 CYP2C9 inhibitor 0.919 0.841 0.823 0.878 0.671 0.905 0.820 0.792 0.876 0.635 0.960 0.880 0.849 0.942 0.755 CYP2C9 substrate 0.725 0.707 0.776 0.606 0.386 0.785 0.744 0.816 0.636 0.461 0.967 0.904 0.911 0.894 0.801 CYP2D6 inhibitor 0.892 0.824 0.823 0.828 0.558 0.882 0.809 0.816 0.780 0.515 0.973 0.884 0.866 0.958 0.715 CYP2D6 substrate 0.847 0.775 0.733 0.818 0.553 0.775 0.663 0.600 0.727 0.330 0.947 0.893 0.849 0.937 0.788 CYP3A4 inhibitor 0.921 0.832 0.825 0.841 0.659 0.921 0.842 0.824 0.869 0.683 0.960 0.891 0.869 0.922 0.781 CYP3A4 substrate 0.776 0.713 0.820 0.608 0.437 0.802 0.753 0.760 0.745 0.505 0.948 0.887 0.920 0.855 0.776 T1/2 0.801 0.727 0.658 0.827 0.478 0.822 0.744 0.750 0.736 0.481 0.948 0.869 0.822 0.938 0.746 hERG Blockers 0.943 0.889 0.869 0.909 0.778 0.947 0.889 0.866 0.912 0.778 0.984 0.936 0.919 0.954 0.873 H-HT 0.814 0.720 0.814 0.650 0.461 0.750 0.675 0.735 0.630 0.362 0.975 0.895 0.976 0.835 0.802 DILI 0.924 0.894 0.826 0.958 0.793 0.849 0.708 0.583 0.833 0.430 0.998 0.981 0.984 0.979 0.963 AMES Toxicity 0.902 0.807 0.732 0.865 0.606 0.876 0.797 0.753 0.831 0.586 0.976 0.917 0.869 0.955 0.832 ROA Toxicity 0.853 0.778 0.769 0.793 0.549 0.846 0.795 0.826 0.744 0.567 0.986 0.936 0.923 0.957 0.868 FDAMDD 0.804 0.736 0.734 0.737 0.471 0.869 0.787 0.766 0.810 0.575 0.986 0.946 0.926 0.970 0.894 Skin Sensitization 0.707 0.775 0.539 0.889 0.462 0.901 0.854 0.692 0.929 0.652 0.991 0.966 0.952 0.973 0.923 Carcinogencity 0.788 0.731 0.623 0.843 0.476 0.694 0.619 0.566 0.673 0.240 0.974 0.909 0.876 0.942 0.817 Eye Corrosion 0.983 0.957 0.965 0.944 0.908 0.982 0.965 0.958 0.977 0.928 1.000 0.995 0.995 0.994 0.989 Eye Irritation 0.982 0.952 0.918 0.964 0.876 0.963 0.931 0.904 0.941 0.825 0.996 0.974 0.983 0.971 0.834 Respiratory Toxicity 0.828 0.764 0.732 0.786 0.514 0.906 0.850 0.836 0.859 0.689 0.989 0.956 0.960 0.954 0.909 NR-AR 0.886 0.890 0.896 0.731 0.348 0.778 0.881 0.898 0.444 0.201 0.991 0.911 0.908 0.986 0.506 NR-AR-LBD 0.915 0.936 0.942 0.783 0.472 0.967 0.948 0.952 0.833 0.545 0.996 0.962 0.960 0.995 0.666 NR-AhR 0.943 0.862 0.858 0.896 0.573 0.873 0.828 0.840 0.737 0.435 0.975 0.891 0.882 0.962 0.655 NR-Aromatase 0.852 0.849 0.859 0.615 0.264 0.895 0.888 0.898 0.654 0.340 0.985 0.914 0.910 0.995 0.552 NR-ER 0.771 0.815 0.845 0.567 0.320 0.781 0.847 0.877 0.603 0.394 0.946 0.885 0.889 0.853 0.587 NR-ER-LBD 0.850 0.903 0.918 0.618 0.364 0.832 0.892 0.907 0.600 0.340 0.987 0.915 0.911 0.993 0.572 NR-PPAR-gamma 0.893 0.896 0.901 0.750 0.344 0.957 0.884 0.887 0.800 0.345 0.989 0.918 0.916 0.994 0.495 SR-ARE 0.863 0.827 0.850 0.701 0.469 0.852 0.841 0.871 0.678 0.483 0.954 0.891 0.888 0.905 0.675 SR-ATAD5 0.874 0.919 0.929 0.640 0.361 0.882 0.913 0.923 0.640 0.348 0.991 0.936 0.934 0.995 0.573 SR-HSE 0.907 0.868 0.875 0.750 0.393 0.855 0.885 0.898 0.667 0.384 0.985 0.908 0.903 0.990 0.582 SR-MMP 0.927 0.897 0.908 0.835 0.660 0.933 0.880 0.896 0.791 0.607 0.979 0.924 0.918 0.957 0.766 SR-p53 0.881 0.841 0.849 0.723 0.365 0.889 0.844 0.846 0.809 0.411 0.982 0.885 0.878 0.995 0.566 Table 4. Results of leave-cluster-out validation of regression models Property R2 MAE RMSE LogS 0.826 0.654 0.855 LogD7.4 0.873 0.409 0.537 LogP 0.961 0.295 0.387 Caco-2 Permeability 0.613 0.343 0.464 MDCK Permeability 0.424 0.415 0.494 PPB 0.769 8.577 0.134 VD 0.392 0.783 1.371 Fu 0.720 0.281 0.368 CL 0.301 3.034 4.437 BCF 0.368 0.789 1.06 IGC50 0.743 0.402 0.549 LC50 0.710 0.641 0.892 LC50DM 0.719 0.772 1.006 Table 5. Results of leave-cluster-out validation of classification models Property ACC AUC MCC Pgp-inhibitor 0.871 0.939 0.719 Pgp-substrate 0.808 0.887 0.618 HIA 0.935 0.959 0.753 F20% 0.811 0.757 0.392 F30% 0.770 0.763 0.355 BBB Penetration 0.809 0.886 0.573 CYP1A2 inhibitor 0.900 0.96 0.800 CYP1A2 substrate 0.722 0.796 0.438 CYP2C19 inhibitor 0.869 0.920 0.693 CYP2C19 substrate 0.657 0.706 0.333 CYP2C9 inhibitor 0.875 0.908 0.608 CYP2C9 substrate 0.621 0.651 0.248 CYP2D6 inhibitor 0.843 0.907 0.561 CYP2D6 substrate 0.716 0.788 0.436 CYP3A4 inhibitor 0.862 0.936 0.704 CYP3A4 substrate 0.787 0.868 0.58 T1/2 0.665 0.729 0.334 hERG Blockers 0.892 0.957 0.754 H-HT 0.625 0.677 0.232 DILI 0.767 0.877 0.556 AMES Toxicity 0.748 0.829 0.497 ROA Toxicity 0.774 0.825 0.509 FDAMDD 0.751 0.846 0.520 Skin Sensitization 0.577 0.689 0.247 Carcinogenicity 0.550 0.594 0.128 Eye Corrosion 0.881 0.960 0.759 Eye Irritation 0.953 0.970 0.721 Respiratory 0.839 0.904 0.661 NR-AR 0.847 0.925 0.508 NR-AR-LBD 0.912 0.955 0.575 NR-AhR 0.785 0.906 0.532 NR-Aromatase 0.758 0.841 0.250 NR-ER 0.742 0.641 0.147 NR-ER-LBD 0.782 0.813 0.242 NR-PPAR-gamma 0.898 0.897 0.283 SR-ARE 0.782 0.809 0.351 SR-ATAD5 0.844 0.836 0.196 SR-HSE 0.814 0.841 0.332 SR-MMP 0.798 0.880 0.477 SR-p53 0.778 0.849 0.358 4. ImplementationADMETlab 2.0 was built using Python web framework of Django and deployed on an elastic compute service from Aliyun running an Ubuntu Linux system. The web access was enabled via the Nginx web server and the interactions between Django and proxy server were supported by uwsgi. This application was developed based on the Model-View-Template (MVT) framework. The model layer maps the business objects to the database objects. The view layer is a business logic layer, responsible for performing the access to the deep learning models, delivering the data to be shown to the template layer, and handling the upload and download of files. The template layer provides the visualization of results, page rendering, integration of documentation, etc. The uploaded and downloaded files, pre-trained models and model predictions are stored in the server. The prediction models were built with the Python programming language. The deep learning packages, PyTorch and DGL, were used in model implementation. Additionally, the RDKit package was employed to provide various cheminformatics support. The server has been successfully tested on the recent version of Mozilla Firefox, Google Chrome and Apple Safari. Table 6. The development environment of ADMETlab 2.0 Third party library Version rdkit 2019.03.1 django 2.2 dgl 0.5.2 dgllife 0.2.5 pytorch 1.6.0 torchvision 0.7.0 pycharts 1.8.1 5. Browser Compatibility OS Version Chrome Edge Firefox Safari Linux Ubuntu&nbsp;18.04.5 LTS 87.0.4280.141 n/a 82.0.2 n/a MacOS Catalina 10.15.6 87.0.4280.141 n/a 84.0.1 13.1.2 Windows 10 88.0.4324.104 88.0.705.53 84.0.2 n/a 4. References Xiong, G., Wu, Z., Yi, J., Fu, L., Yang, Z., Hsieh, C., Yin, M., Zeng, X., Wu, C., Lu, A., Chen, X., Hou, T., &amp; Cao, D. ADMETlab 2.0: an integrated online platform for accurate and comprehensive predictions of ADMET properties. Nucleic Acids Res, 2021, doi: 10.1093/nar/gkab255.","categories":[{"name":"研究成果","slug":"研究成果","permalink":"http://example.com/categories/%E7%A0%94%E7%A9%B6%E6%88%90%E6%9E%9C/"}],"tags":[{"name":"Nucleic Acids Research","slug":"Nucleic-Acids-Research","permalink":"http://example.com/tags/Nucleic-Acids-Research/"},{"name":"Project","slug":"Project","permalink":"http://example.com/tags/Project/"},{"name":"ADMET","slug":"ADMET","permalink":"http://example.com/tags/ADMET/"}]},{"title":"Review: Artificial Intelligence in Drug Discovery: Applications and Techniques","slug":"AIDD-A-and-T","date":"2021-07-21T14:31:45.000Z","updated":"2021-07-26T06:34:16.000Z","comments":true,"path":"article/2e5d82da.html","link":"","permalink":"http://example.com/article/2e5d82da.html","excerpt":"今天看了一篇综述，受益良多，对一些内容做一下总结","text":"今天看了一篇综述，受益良多，对一些内容做一下总结 论文链接: Artificial Intelligence in Drug Discovery: Applications and Techniqueshttps://www.researchgate.net/publication/352308845_Artificial_Intelligence_in_Drug_Discovery_Applications_and_Techniques Github地址： A Survey of Artificial Intelligence in Drug Discoveryhttps://github.com/dengjianyuan/Survey_AI_Drug_Discovery 1. 摘要人工智能(AI)在过去十年中一直在改变着药物发现(drug discovery)的实践。各种人工智能技术已被用于广泛的应用中，如虚拟筛选和药物设计。在这项调查中，我们首先对药物发现进行了概述，并讨论了相关的应用，这些应用可以简化为两个主要任务，即分子性质预测和分子生成。此外，为了总结人工智能在药物发现方面的进展，我们介绍了相关的人工智能技术，包括所调查论文中的模型架构和学习范式。我们希望这项调查能够为那些有兴趣在AI+药物发现领域的研究人员提供指导。我们还提供了一个GitHub资源库https://github.com/dengjianyuan/Survey_AI_Drug_Discovery，其中收集了论文和代码，作为学习资源，定期更新。 2. 关键概念定义Table 1 关键概念定义 Term Description Drug Discovery (药物发现) 药物发现是在没有药物治疗某疾病或现有药物疗效有限(和/或)毒性严重的情况下进行的项目。 leads drug candidates High-Throughput Screening (HTS) a hit-finding approach underpinned by development in automation and the availability of large chemical libraries SAR structure-activity relationship Virtual Screening (VS) Various computational techniques have been developed to search the large chemical libraries for potentially active molecules to be tested in subsequent in vitro and in vivo assays. structure-based VS based on knowledge about the target -&gt; increase the odds of identifying active molecules. ligand-based VS based on knowledge about known active ligands -&gt; increase the odds of identifying active molecules. agonist 一种作为内源性配体激活靶点并发挥生物反应的分子 antagonist 结合靶标以抑制反应的分子。 physicochemical property water solubility, acid-base dissociation constant, lipophilicity, permeability… pharmacokinetic property absorption, distribution, metabolism, excretion pharmacodynamic property activity, selectivity Synthetic Accessibility Score (SAS) SAS is a heuristic score (10-1) of how hard or easy it is to synthesize a given molecule based on a combination of the molecular fragments’ contributions. Quantitative Estimation of Drug-likeness (QED) QED is an estimate (0-1) on how likely a molecule is a viable drug candidate. quantitative structure-activity relationship (QSAR) 对于每个感兴趣的属性，建立一个预测模型，通过分类或回归将分子结构映射到属性值。 design-make-test-analysis (DMTA) cycle 设计、制造、测试和分析周期 3. 数据, 表征, 基准Figure 1 AI驱动药物发现中的应用和技术概述 1. 公开数据资源 Data Resources Description Link PubChem PubChem是全球最大的化学数据库，收集了750个数据源的化学信息。截至2020年8月，PubChem包含1.11亿个独特的化学结构，来自120万个生物分析实验的2.71亿个活性数据点。 view ChEMBL 一个包含7700万SMILES字符串的精选数据集(from PubChem)。在ChEMBL22 (version 22)中，有超过160万种不同的化学结构，活性值超过1400万。 view ZINC 用于目标预测的大规模基准数据集。由UCSF的Irwin和Shoichet实验室开发，包含分子，注释配体和靶标，以及超过1.2亿类药物化合物。 view PDBbind PDBbind数据库的目的是提供储存在蛋白质数据库(PDB)中所有类型生物分子复合物的实验测量的结合亲和力数据的全面收集。它为这些复合物的能量信息和结构信息之间提供了必要的联系，有助于生物系统分子识别的各种计算和统计研究。 view BindingDB BindingDB是一个公共的、可在网上访问的测量结合亲和力的数据库，主要关注被认为是药物靶点的蛋白质与小的、类药物分子的相互作用。截至2021年7月4日，BindingDB包含41,300个条目，每个条目都有一个DOI，包含8,547个蛋白质靶标和992,030个小分子的2,295,072个结合数据。 view DUD 用于基准测试虚拟筛选。 view DUD-E 增强和重建版本的DUD，DUD-E旨在通过提供具有挑战性的decoys来帮助基准分子对接计划 view MUV 这些数据集提供了一个用于最大无偏验证 (MUV)的虚拟筛选方法的工具。 view STITCH 化学-蛋白质相互作用网络 view GLL&amp;GDD The GDD, a GPCR Decoy Database, with its accompanying GPCR Ligand Library (GLL) have been compiled to help in GPCR docking. view NRLiSt BDB 一个非商业性的人工管理基准数据库，专门用于核受体(Nuclear Receptor, NR)配体和结构药理学档案。 view KEGG KEGG是一个从分子水平信息，特别是基因组测序等高通量实验技术生成的大规模分子数据集，了解细胞、生物、生态系统等生物系统的高级功能和用途的数据库 view DrugBank 一个全面的免费在线数据库，包含有关药物和药物目标的信息。 view SIDER SIDER包含已上市药品及其记录的药物不良反应的信息。信息是从公共文档和第三方库提取的。现有信息包括副作用频率、药物和副作用分类以及进一步信息的链接，例如药物靶标关系。 view OFFSIDES 一个关于药物副作用的数据库，但并没有在FDA的官方标签上列出。是唯一全面的双方药效库。超过3300种药物和63000种组合与数百万种潜在的不良反应有关。 view TWO-SIDES TWO-SIDES数据库是关于药物的多药副作用的资源。该数据库包含59,220对药物和1301个不良事件之间的868,221个显著关联。这些关联仅限于那些不能明确归因于任何一种药物单独的关联(即OFFSIDES所涵盖的关联)。根据比例报告比率(PRR)，该数据库还包含另外3782910个显著关联，其中药物对的副作用关联评分高于单独的药物。 view DILIrank DILIrank DataSet是LTKB基准数据集的更新版本。DILIrank由1,036种FDA批准的药物组成，根据其导致药物诱导的肝损伤 (drug-induced liver injury, DILI)的可能性分为四类。DILI分类衍生自分析FDA批准的药物标签文件中提出的肝毒性描述，并评估文档中的因果关系。具体而言，这一最大的公开注释的DILI数据集包含三组 (Most-，Less- 和 No-DILI)，并将药物与肝损伤联系起来的证据，以及一个额外的分组 (Ambiguous-DILI-concern)，因果关系未确定。 view 2. 小分子表征Figure 2 小分子表征插图 综述文章: Molecular representations in AI‑driven drug discovery: a review and practical guide (J Cheminf 2020)https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-00460-5 3. 基准平台Table 2 基准平台总结 Benchmark platforms Description Link MoleculeNet MoleculeNet: a benchmark for molecular machine learning (Chem Sci 2018) paper code download MolMapNet Out-of-the-box deep learning prediction of pharmaceutical properties by broadly learned knowledge-based molecular representations (Nat Mach Intell 2021) paper code ChemProp Analyzing Learned Molecular Representations for Property Prediction (J Chem Inf Model 2019) paper code website REINVENT Molecular De Novo design using Recurrent Neural Networks and Reinforcement Learning (J Cheminf 2017) paper code REINVENT 2.0 an AI Tool for De Novo Drug Design (J Chem Inf Model 2020) paper code GraphINVENT Graph Networks for Molecular Design (aka: GraphINVENT; ChemRxiv 2020) paper code GraphINVENT Practical Notes on Building Molecular Graph Generative Models (Applied AI Letters 2020) paper code Guacamol GuacaMol: Benchmarking Models for de Novo Molecular Design (J Chem Inf Model 2019) paper code MOSES Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models (Front Pharmacol 2020) paper code *. 评价指标Table 3 分子性质预测和分子生成的评价指标 Metric Definition Task Type Accuracy Correctly predictive rate Classification Recall True positive rate Classification Precision Positive predictive value Classification AUROC Area under receiver-operating curve Classification AUPRC Area under precision-recall curve Classification Recall@k Recall among top-k retrieved molecules Retrieval Precision@k Precision among top-k retrieved molecules Retrieval AP Average Precision Retrieval MAE Mean absolute error Regression RMSE Rooted mean squared error Regression Validity Fraction of valid molecules Distribution learning Uniqueness@k Fraction of non-duplicates in k valid molecules Distribution learning Novelty Fraction of molecules not shown in training set Distribution learning Diversity Chemical diversity within generated molecules Distribution learning FCD Fŕechet ChemNet Distance Distribution learning KL Divergence Kullback-Leibler Divergence Distribution learning Scaffold Similarity Similarity based on Bemis–Murcko scaffold Goal-directed design Rediscovery Ability to re-discover target molecule Goal-directed design 4. 模型架构1. 卷积神经网络 (CNN) Task: Molecular Property Prediction; Representation*: images NameDefinitionLink-Convolutional Embedding of Attributed Molecular Graphs for Physical Property Prediction (J Chem Inf Model 2017)paperChemceptionChemception: a deep neural network with minimal chemistry knowledge matches the performance of expert-developed QSAR/QSPR models (aka: Chemception; arXiv 2017)paperToxic ColorsToxic Colors: The Use of Deep Learning for Predicting Toxicity of Compounds Merely from Their Graphic Images (aka: Toxic Colors; J Chem Inf Model 2018)paperKekuleScopeKekuleScope: prediction of cancer cell line sensitivity and compound potency using convolutional neural networks trained on compound images (J Cheminf 2019)paper code-Learning Drug Functions from Chemical Structures with Convolutional Neural Networks and Random Forests (J Chem Inf Model 2019)paperDEEPScreenDEEPScreen: high performance drug–target interaction prediction with convolutional neural networks using 2-D structural compound representation (Chem Sci 2020)paper code Task: Molecular Property Prediction; Representation*: fingerprint NameDefinitionLink-Massively Multitask Networks for Drug Discovery (arXiv 2015)paper-Convolutional Networks on Graphs for Learning Molecular Fingerprints (NeurIPS 2015)paper code Task: Molecular Structure Extraction and Recognition NameDefinitionLinkMSE-DUDLMolecular Structure Extraction from Documents Using Deep Learning (J Chem Inf Model 2019)paperDECIMER-SegmentationDECIMER-Segmentation: Automated extraction of chemical structure depictions from scientific literature (J Cheminf 2021)paperDECIMERDECIMER: towards deep learning for chemical image recognition (J Cheminf 2020)paper codeDECIMER 1.0DECIMER 1.0: Deep Learning for Chemical Image Recognition using Transformers (chemRxiv 2021)paper 2. 递归神经网络 (RNN) Task: Molecular Property Prediction; Representation*: SMILES Strings NameDefinitionLinkSMILES2VecSMILES2Vec: An Interpretable General-Purpose Deep Neural Network for Predicting Chemical Properties (aka: SMILES2Vec; arXiv 2017)paper-Large-scale comparison of machine learning methods for drug target prediction on ChEMBL (aka:SmilesLSTM; Chem Sci 2018)paper code Task: Molecule Generation; Representation*: SMILES Strings NameDefinitionLink-Molecular de‑novo design through deep reinforcement learning (aka: REINVENT; J Cheminf 2017)paper-Generating Focused Molecule Libraries for Drug Discovery with Recurrent Neural Networks (aka: CharRNN; ACS Cent Sci 2018)paper-Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design (ICLR 2018 Workshop)paperReLeaSEDeep Reinforcement Learning for de novo Drug Design（aka: ReLeaSE; Sci Adv 2018）paper codeDeepFMPODeep Reinforcement Learning for Multiparameter Optimization in de novo Drug Design (J Chem Inf Model 2019)paper code Task: Molecule Generation; Representation*: Molecular Graphs NameDefinitionLinkGraphRNNGraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models (aka: GraphRNN; ICML 2018)paper code-Learning Deep Generative Models of Graphs (ICML 2018)paper codeMolecularRNNMolecularRNN: Generating realistic molecular graphs with optimized properties (arXiv 2019)paper 3. 图神经网络 (GNN) Task: Molecular Property Prediction; Representation*: Molecular Graphs WorkLinkMolecular Graph Convolutions: Moving Beyond Fingerprints (aka: Weave; J Comput Aided Mol Des 2016)paperConvolutional Embedding of Attributed Molecular Graphs for Physical Property Prediction (J Chem Inf Model 2017)paperSemi-supervised classification with graph convolutional networks (aka: GraphConv; ICLR 2017)paper codeNeural Message Passing for Quantum Chemistry (aka: MPNN; ICML 2017)paper codeSchNet: A continuous-filter convolutional neural network for modeling quantum interactions (aka: SchNet; NeurIPS 2017)paper codeLow Data Drug Discovery with One-Shot Learning (ACS Cent Sci 2017)paperLarge-scale comparison of machine learning methods for drug target prediction on ChEMBL (aka:SmilesLSTM; Chem Sci 2018)paper codePotentialNet for Molecular Property Prediction (aka: PotentialNet; ACS Cent Sci 2018)paperMolecular Property Prediction: A Multilevel Quantum Interactions Modeling Perspective (aka: MGCN; AAAI 2019)paperDeep Learning-Based Prediction of Drug-Induced Cardiotoxicity (J Chem Inf Model 2019)paper codeDeepChemStable: Chemical Stability Prediction with an Attention-Based Graph Convolution Network (J Chem Inf Model 2019)paperAnalyzing Learned Molecular Representations for Property Prediction (aka: Chemrop, D-MPNN; J Chem Inf Model 2019)paper codeMolecule Property Prediction Based on Spatial Graph Embedding (aka: C-SGEN; J Chem Inf Model 2019)paper codePushing the Boundaries of Molecular Representation for Drug Discovery with the Graph Attention Mechanism (aka: Attentive FP; J Med Chem 2019)paper codeGraph convolutional neural networks as” general-purpose” property predictors: the universality and limits of applicability (J Chem Inf Model 2020)paperN-Gram Graph: Simple Unsupervised Representation for Graphs, with Applications to Molecules (aka: N-Gram Graph; NeurIPS 2019)paperBuilding attention and edge message passing neural networks for bioactivity and physical–chemical property prediction (J Cheminf 2020)paper codeA self‑attention based message passing neural network for predicting molecular lipophilicity and aqueous solubility (J Cheminf 2020)paper codeChemically Interpretable Graph Interaction Network for Prediction of Pharmacokinetic Properties of Drug-Like Molecules (aka: CIGIN; AAAI 2020)paper codeStrategies for Pre-training Graph Neural Networks (ICLR 2020)paper codeDirectional Message Passing for Molecular Graphs (aka: DimeNet; ICLR 2020)paper codeDrug–target affinity prediction using graph neural network and contact maps (RSC Advances 2020)paperASGN: An Active Semi-supervised Graph Neural Network for Molecular Property Prediction (aka: ASGN; KDD 2020)paper codeMeta-Learning GNN Initializations for Low-Resource Molecular Property Prediction (ICML 2020 Workshop)paper code Task: Molecule Generation; Representation*: Molecular Graphs WorkLinkMulti‑objective de novo drug design with conditional graph generative model (J Cheminf 2018)paper codeGraph Convolutional Policy Network for Goal-Directed Molecular Graph Generation (aka: GCPN; NeurIPS 2018)paper codeOptimization of Molecules via Deep Reinforcement Learning (aka: MolDQN; Sci Rep 2019)paperImproving Molecular Design by Stochastic Iterative Target Augmentation (ICML 2020)paper codeDeepGraphMolGen, a multi‑objective, computational strategy for generating molecules with desirable properties: a graph convolution and reinforcement learning approach (J Cheminf 2020)paperReinforced Molecular Optimization with Neighborhood-Controlled Grammars (aka: MNCE-RL; NeurIPS 2020)paper codeGraph Networks for Molecular Design (aka: GraphINVENT; ChemRxiv 2020)paper code Common GNN Models WorkLinkRecurrent GNNs Gated graph sequence neural networks (aka: GGNN; ICLR 2016)paper codeConvolutional GNNs (Spectral-based) Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering (aka: ChebNet; NeurIPS 2016)paper codeConvolutional GNNs (Spectral-based) Semi-supervised classification with graph convolutional networks (aka: GraphConv; ICLR 2017)paper codeConvolutional GNNs (Spatial-based) Neural message passing for quantum chemistry (aka: MPNN; ICML 2017)paper codeConvolutional GNNs (Spatial-based) Inductive Representation Learning on Large Graphs (aka: GraphSAGE; NeurIPS 2017)paper codeConvolutional GNNs (Spatial-based) Graph Attention Networks (aka: GAT; ICLR 2018)paper codeConvolutional GNNs (Spatial-based) How powerful are graph neural networks? (aka: GIN; ICLR 2019)paper code 4. 变分编码器 (VAE) Task: Molecule Generation; Representation*: SMILES Strings WorkLinkAutomatic chemical design using a data-driven continuous representation of molecules (arXiv 2016; ACS Cent Sci 2018)paper codeGrammar Variational Autoencoder (aka: GrammarVAE; ICML 2017)paperApplication of Generative Autoencoder in De Novo Molecular Design (Mol Inform 2017)paperSyntax-Directed Variational Autoencoder for Structured Data (aka: SD-VAE; ICLR 2018)paper codeConditional Molecular Design with Deep Generative Models (aka: Continuous SSVAE; J Chem Inf Model 2018)paper codeMolecular generative model based on conditional variational autoencoder for de novo molecular design (aka: CVAE; J Cheminf 2018)paper codeConstrained Graph Variational Autoencoders for Molecule Design (aka: CGVAE; NeurIPS 2018)paper codeNEVAE: A Deep Generative Model for Molecular Graphs (aka: NeVAE; AAAI 2019)paper codeDe Novo Molecular Design by Combining Deep Autoencoder Recurrent Neural Networks with Generative Topographic Mapping (aka: GTMVAE; J Chem Inf Model 2019)paperRe-balancing Variational Autoencoder Loss for Molecule Sequence Generation (aka: re-balanced VAE; ACM BCB 2020)paper codeCogMol: Target-Specific and Selective Drug Design for COVID-19 Using Deep Generative Models (aka: CogMol; NeurIPS 2020)paper code VAE变体: AAE WorkLinkApplication of Generative Autoencoder in De Novo Molecular Design (Mol Inform 2017)paperdruGAN: An Advanced Generative Adversarial Autoencoder Model for de Novo Generation of New Molecules with Desired Molecular Properties in Silico (aka: druGAN; Mol Pharm 2017)paperEntangled Conditional Adversarial Autoencoder for de Novo Drug Discovery (aka: SAAE; Mol Pharm 2018)paper Task*: Molecule Generation; Representation*: Molecular Graphs WorkLinkGraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders (aka: GraphVAE; arXiv 2018)paperJunction Tree Variational Autoencoder for Molecular Graph Generation (aka: JT-VAE; ICML 2018)paper codeConstrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders (aka:Regularized VAE; NeurIPS 2018)paperMolecular Hypergraph Grammar with Its Application to Molecular Optimization (aka: MHG-VAE; ICML 2019)paper codeEfficient learning of non‑autoregressive graph variational autoencoders for molecular graph generation (J Cheminf 2019)paper codeDeep learning enables rapid identification of potent DDR1 kinase inhibitors (aka: GENTRL; Nat Biotechnol 2019)paper codeScaffold-based molecular design using graph generative model (aka: ScaffoldVAE; arXiv 2019)paperLearning Multimodal Graph-to-Graph Translation for Molecule Optimization (aka: VJTNN; ICLR 2019)paper codeCORE: Automatic Molecule Optimization Using Copy &amp; Refine Strategy (AAAI 2020)paper codeHierarchical Generation of Molecular Graphs using Structural Motifs (aka: HierVAE; ICML 2020)paper codeCompressed graph representation for scalable molecular graph generation (J Cheminf 2020)paper code Task*: Reaction & Retrosynthesis Prediction; Representation*: Molecular Graphs WorkLinkGenerating Molecules via Chemical Reactions (ICLR 2019 Workshop)paperBarking up the right tree: an approach to search over molecule synthesis DAG (NeurIPS 2020)paper codepaper 5. 对抗生成网络 (GAN) Task: Molecule Generation; Representation*: SMILES Strings WorkLinkObjective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models (aka: ORGAN; ArXiv 2017)paper codeOptimizing distributions over molecular space. An objective-reinforced generative adversarial network for inverse-design chemistry (aka: ORGANIC; ChemRxiv 2017)paper codeReinforced Adversarial Neural Computer for de Novo Molecular Design (aka: RANC; J Chem Inf Model 2018)paper Task*: Molecule Generation; Representation*: Molecular Graphs WorkLinkMolGAN: An implicit generative model for small molecular graphs (aka: MolGAN; ICML 2018 Workshop)paper code-tensorflow code-pytorch 6. Normalizing Flow Models Task*: Molecule Generation; Representation*: Molecular Graphs WorkLinkGraphNVP: An Invertible Flow Model for Generating Molecular Graphs (aka: GraphNVP; arXiv 2019)paper codeGraph Residual Flow for Molecular Graph Generation (aka: GRF; arXiv 2019)paperGraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation (aka: GraphAF; ICLR 2020)paper codeMoFlow: An Invertible Flow Model for Generating Molecular Graphs (aka: MoFlow; KDD 2020)paper codeGraphDF: A Discrete Flow Model for Molecular Graph Generation (aka: GraphDF; ICML 2021)paper 7. Transformers Task*: Molecular Property Prediction; Representation*: SMILES Strings WorkLinkSMILES-BERT: Large Scale Unsupervised Pre-Training for Molecular Property Prediction (aka: SMILES-BERT; ACM BCB 2019)paperSMILES Transformer: Pre-trained Molecular Fingerprint for Low Data Drug Discovery (aka: SMILES Transformer; arXiv 2019)paper codeChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction (aka: ChemBERTa; arXiv 2020)paper codeMolecular representation learning with language models and domain-relevant auxiliary tasks (aka: MolBERT; NeurIPS 2020 Workshop)paper code Task*: Molecular Property Prediction; Representation*: Molecular Graphs WorkLinkSelf-Supervised Graph Transformer on Large-Scale Molecular Data (aka: GROVER; NeurIPS 2020)paper Task*: Molecule Generation; Representation*: Molecular Graphs WorkLinkA Model to Search for Synthesizable Molecules (aka: Molecule Chef; NeurIPS 2019)paper codeTransformer neural network for protein-specific de novo drug generation as a machine translation problem (Sci Rep 2021)paper 5. 学习范式1. 分子性质预测中的自监督学习 Generative Learning WorkLinkStrategies for Pre-training Graph Neural Networks (ICLR 2020)paper codeMolecular representation learning with language models and domain-relevant auxiliary tasks (aka: MolBERT; NeurIPS 2020 Workshop)paper codeSelf-Supervised Graph Transformer on Large-Scale Molecular Data (aka: GROVER; NeurIPS 2020)paper Contrastive Learning WorkLinkMolCLR: Molecular Contrastive Learning of Representations via Graph Neural Networks (ArXiv 2021)paper 2. 分子生成中的强化学习 Reinforcement Learning in Molecule Generation WorkLinkObjective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models (aka: ORGAN; ArXiv 2017)paper codeMolecular de‑novo design through deep reinforcement learning (aka: REINVENT; J Cheminf 2017)paperOptimizing distributions over molecular space. An objective-reinforced generative adversarial network for inverse-design chemistry (aka: ORGANIC; ChemRxiv 2017)paper codeReinforced Adversarial Neural Computer for de Novo Molecular Design (aka: RANC; J Chem Inf Model 2018)paperExploring Deep Recurrent Models with Reinforcement Learning for Molecule Design (ICLR 2018 Workshop)paperMolGAN: An implicit generative model for small molecular graphs (aka: MolGAN; ICML 2018 Workshop)paper code-tensorflow code-pytorchDeep Reinforcement Learning for de novo Drug Design（aka: ReLeaSE; Sci Adv 2018)paper codeGraph Convolutional Policy Network for Goal-Directed Molecular Graph Generation (aka: GCPN; NeurIPS 2018)paper codeDeep learning enables rapid identification of potent DDR1 kinase inhibitors (aka: GENTRL; Nat Biotechnol 2019)paper codeDeep Reinforcement Learning for Multiparameter Optimization in de novo Drug Design (aka: DeepFMPO; J Chem Inf Model 2019)paper codeOptimization of Molecules via Deep Reinforcement Learning (aka: MolDQN; Sci Rep 2019)paperEfficient learning of non‑autoregressive graph variational autoencoders for molecular graph generation (J Cheminf 2019)paper codeGraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation (aka: GraphAF; ICLR 2020)paper codeReinforcement Learning for Molecular Design Guided by Quantum Mechanics (cka: MolGym; ICML 2020)paperDeepGraphMolGen, a multi‑objective, computational strategy for generating molecules with desirable properties: a graph convolution and reinforcement learning approach (aka: DeepGraphMolGen; J Cheminf 2020)paperReinforced Molecular Optimization with Neighborhood-Controlled Grammars (aka: MNCE-RL; NeurIPS 2020)paper code Common RL Algorithms WorkLinkValue-based Playing Atari with Deep Reinforcement Learning (aka: DQN; NeurIPS Workshop 2013)paperValue-based Human-level control through deep reinforcement learning (aka: DQN; Nature 2015)paperValue-based Deep Reinforcement Learning with Double Q-learning (aka: Double Q-learning; AAAI 2016)paperValue-based Prioritized Experience Replay (aka: DQN with Experience Replay; ICLR 2016)paperValue-based Dueling Network Architectures for Deep Reinforcement Learning (aka: Dueling Network; ICML 2016)paperPolicy-gradient Simple statistical gradient-following algorithms for connectionist reinforcement learning (aka: REINFORCE; Mach Learn 1992)paperPolicy-gradient Policy Gradient Methods for Reinforcement Learning with Function Approximation (aka: Random Policy Gradient; NeurIPS 1999)paperPolicy-gradient Deterministic Policy Gradient Algorithms (aka: DPG; ICML 2014)paperPolicy-gradient Trust Region Policy Optimization (aka: TRPO; ICML 2015)paperPolicy-gradient Proximal Policy Optimization Algorithms (aka: PPO; arXiv 2017 2015)paperHybrid Continuous control with deep reinforcement learning (aka: DDPG; ICLR 2016)paperHybrid Asynchronous Methods for Deep Reinforcement Learning (aka: A3C; ICML 2016)paper Pareto Optimality (帕累托最优) WorkLinkDe Novo Drug Design of Targeted Chemical Libraries Based on Artificial Intelligence and Pair-Based Multiobjective Optimization (J Chem Inf Model 2020)paper codeMultiobjective de novo drug design with recurrent neural networks and nondominated sorting (J Cheminf 2020)paperDrugEx v2: De Novo Design of Drug Molecule by Pareto-based Multi-Objective Reinforcement Learning in Polypharmacology (ChemRxiv)paperpaper Reaction & Retrosynthesis Optimization WorkLinkOptimizing chemical reactions with deep reinforcement learning (ACS Cent Sci 2017)paper 3. Other Metric Learning WorkLinkMachine-guided representation for accurate graph-based molecular machine learning (Phys Chem Chem Phys 2020)paperEmbedding of Molecular Structure Using Molecular Hypergraph Variational Autoencoder with Metric Learning (Mol Inform 2020)paper Few-Shot Learning WorkLinkLow Data Drug Discovery with One-Shot Learning (ACS Cent Sci 2017)paperpaper Meta Learning WorkLinkMeta-Learning GNN Initializations for Low-Resource Molecular Property Prediction (ICML 2020 Workshop)paper code Active Learning WorkLinkASGN: An Active Semi-supervised Graph Neural Network for Molecular Property Prediction (aka: ASGN; KDD 2020)paper codeEvidential Deep Learning for Guided Molecular Property Prediction and Discovery (NeurIPS 2020 Workshop)paper 6. 解决现有挑战1. Model Interpretation Work Link Drug Discovery Maps, a Machine Learning Model That Visualizes and Predicts Kinome−Inhibitor Interaction Landscapes (J Chem Inf Model 2018) paper Using attribution to decode binding mechanism in neural network models for chemistry (PNAS 2019) paper Interpretation of QSAR Models by Coloring Atoms According to Changes in Predicted Activity: How Robust Is It? (J Chem Inf Model 2019) paper Building of Robust and Interpretable QSAR Classification Models by Means of the Rivality Index (J Chem Inf Model 2019) paper 2. Dataset Concerns Work Link In Need of Bias Control: Evaluating Chemical Data for Machine Learning in Structure-Based Virtual Screening (J Chem Inf Model 2019) paper Deep Learning-Based Imbalanced Data Classification for Drug Discovery (J Chem Inf Model 2020) paper code 3. Uncertainty Estimation Work Link General Approach to Estimate Error Bars for Quantitative Structure−Activity Relationship Predictions of Molecular Activity (J Chem Inf Model 2018) paper Assessment and Reproducibility of Quantitative Structure−Activity Relationship Models by the Nonexpert (J Chem Inf Model 2018) paper Deep Confidence: A Computationally Efficient Framework for Calculating Reliable Prediction Errors for Deep Neural Networks (J Chem Inf Model 2018) paper Reliable Prediction Errors for Deep Neural Networks Using Test-Time Dropout (J Chem Inf Model 2019) paper Minimal-uncertainty prediction of general drug-likeness based on Bayesian neural networks (Nat Mach Intell 2020) paper Assigning Confidence to Molecular Property Prediction (arXiv 2021) paper Gi and Pal Scores: Deep Neural Network Generalization Statistics (ICLR 2021 Workshop) paper 4. Representation Capacity Work Link Ligand-Based Virtual Screening Using Graph Edit Distance as Molecular Similarity Measure (J Chem Inf Model 2019) paper Optimal Transport Graph Neural Networks (arXiv 2020) paper 5. Out-of-Distribution Generalization Work Link Dissecting Machine-Learning Prediction of Molecular Activity: Is an Applicability Domain Needed for Quantitative Structure−Activity Relationship Models Based on Deep Neural Networks? (J Chem Inf Model 2018) paper Most Ligand-Based Classification Benchmarks Reward Memorization Rather than Generalization (J Chem Inf Model 2018) paper Molecular Similarity-Based Domain Applicability Metric Efficiently Identifies Out-of-Domain Compounds (J Chem Inf Model 2018) paper 7. 参考文献 Deng, Jianyuan &amp; Yang, Zhibo &amp; Ojima, Iwao &amp; Samaras, Dimitris &amp; Wang, Fusheng. (2021). Artificial Intelligence in Drug Discovery: Applications and Techniques.","categories":[{"name":"博文阅览","slug":"博文阅览","permalink":"http://example.com/categories/%E5%8D%9A%E6%96%87%E9%98%85%E8%A7%88/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"Drug Discovery","slug":"Drug-Discovery","permalink":"http://example.com/tags/Drug-Discovery/"}]}],"categories":[{"name":"杂货间","slug":"杂货间","permalink":"http://example.com/categories/%E6%9D%82%E8%B4%A7%E9%97%B4/"},{"name":"研究成果","slug":"研究成果","permalink":"http://example.com/categories/%E7%A0%94%E7%A9%B6%E6%88%90%E6%9E%9C/"},{"name":"博文阅览","slug":"博文阅览","permalink":"http://example.com/categories/%E5%8D%9A%E6%96%87%E9%98%85%E8%A7%88/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://example.com/tags/Hexo/"},{"name":"Nucleic Acids Research","slug":"Nucleic-Acids-Research","permalink":"http://example.com/tags/Nucleic-Acids-Research/"},{"name":"Project","slug":"Project","permalink":"http://example.com/tags/Project/"},{"name":"ADMET","slug":"ADMET","permalink":"http://example.com/tags/ADMET/"},{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"Drug Discovery","slug":"Drug-Discovery","permalink":"http://example.com/tags/Drug-Discovery/"}]}